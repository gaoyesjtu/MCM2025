import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import differential_evolution, minimize
from sklearn.cluster import KMeans
import warnings

warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False


class EnhancedMedicalRiskFunction:
    """å¢å¼ºçš„åŒ»å­¦é£é™©å‡½æ•°ï¼šè¿‡æ™šæ£€æµ‹ç”¨æ›´é™¡å³­çš„åˆ†æ®µæŒ‡æ•°å‡½æ•°ï¼Œè¿‡æ—©æ£€æµ‹ç”¨äºŒæ¬¡å‡½æ•°"""

    def __init__(self,
                 early_quadratic_coeff=0.015,
                 late_exp_base_1=0.3, late_exp_rate_1=0.15,
                 late_exp_base_2=2.5, late_exp_rate_2=0.40,
                 late_exp_base_3=6.0, late_exp_rate_3=0.65,
                 base_risk=1.0):
        """
        é£é™©å‡½æ•°å‚æ•°ï¼ˆå¢å¼ºè¿‡æ™šæ£€æµ‹æ–œç‡ï¼‰ï¼š

        è¿‡æ—©æ£€æµ‹ï¼ˆtest_time < reach_timeï¼‰ï¼š
        - early_quadratic_coeff: äºŒæ¬¡å‡½æ•°ç³»æ•°

        è¿‡æ™šæ£€æµ‹ï¼ˆtest_time > reach_timeï¼‰åˆ†æ®µæŒ‡æ•°ï¼š
        - ç¬¬1æ®µ (0 â‰¤ delay â‰¤ 12): base_1 * exp(rate_1 * delay)
        - ç¬¬2æ®µ (12 < delay â‰¤ 27): base_2 * exp(rate_2 * (delay-12))
        - ç¬¬3æ®µ (delay > 27): base_3 * exp(rate_3 * (delay-27))

        - base_risk: åŸºç¡€é£é™©
        """
        self.early_quadratic_coeff = early_quadratic_coeff
        self.late_exp_base_1 = late_exp_base_1
        self.late_exp_rate_1 = late_exp_rate_1
        self.late_exp_base_2 = late_exp_base_2
        self.late_exp_rate_2 = late_exp_rate_2
        self.late_exp_base_3 = late_exp_base_3
        self.late_exp_rate_3 = late_exp_rate_3
        self.base_risk = base_risk

    def calculate_individual_risk(self, test_time, reach_time):
        """è®¡ç®—å•ä¸ªå­•å¦‡çš„é£é™©"""

        if test_time <= reach_time:
            # è¿‡æ—©æ£€æµ‹ï¼šäºŒæ¬¡å‡½æ•°é£é™©
            time_diff = reach_time - test_time
            early_risk = self.early_quadratic_coeff * (time_diff ** 2) + 0.2
            return self.base_risk + early_risk

        else:
            # è¿‡æ™šæ£€æµ‹ï¼šåˆ†æ®µæŒ‡æ•°å‡½æ•°é£é™©
            delay = test_time - reach_time

            # if delay <= 12:
                # ç¬¬1æ®µï¼šç›¸å¯¹æ¸©å’Œçš„æŒ‡æ•°å¢é•¿
            late_risk = self.late_exp_base_1 * np.exp(self.late_exp_rate_1 * delay)
            '''elif delay <= 27:
                # ç¬¬2æ®µï¼šä¸­ç­‰çš„æŒ‡æ•°å¢é•¿ï¼ˆæ–œç‡æ˜¾è‘—å¢å¤§ï¼‰
                # ç¡®ä¿è¿ç»­æ€§
                boundary_1 = self.late_exp_base_1 * np.exp(self.late_exp_rate_1 * 12)
                late_risk = boundary_1 + self.late_exp_base_2 * np.exp(self.late_exp_rate_2 * (delay - 12))
            else:
                # ç¬¬3æ®µï¼šæ€¥å‰§çš„æŒ‡æ•°å¢é•¿ï¼ˆæ–œç‡æå¤§ï¼‰
                # ç¡®ä¿è¿ç»­æ€§
                boundary_1 = self.late_exp_base_1 * np.exp(self.late_exp_rate_1 * 12)
                boundary_2 = boundary_1 + self.late_exp_base_2 * np.exp(self.late_exp_rate_2 * 15)  # 27-12=15
                late_risk = boundary_2 + self.late_exp_base_3 * np.exp(self.late_exp_rate_3 * (delay - 27))'''

            return self.base_risk + late_risk

    def calculate_group_risk(self, test_time, reach_times, return_details=False):
        """è®¡ç®—ä¸€ç»„å­•å¦‡çš„å¹³å‡é£é™©"""
        individual_risks = []
        early_count = 0
        late_count = 0
        on_time_count = 0

        for reach_time in reach_times:
            risk = self.calculate_individual_risk(test_time, reach_time)
            individual_risks.append(risk)

            if test_time < reach_time:
                early_count += 1
            elif test_time > reach_time:
                late_count += 1
            else:
                on_time_count += 1

        avg_risk = np.mean(individual_risks)
        detection_success_rate = np.mean([reach_time <= test_time for reach_time in reach_times])

        if return_details:
            return {
                'avg_risk': avg_risk,
                'detection_success_rate': detection_success_rate,
                'early_count': early_count,
                'late_count': late_count,
                'on_time_count': on_time_count,
                'individual_risks': individual_risks
            }
        else:
            return avg_risk, detection_success_rate

    def plot_risk_function(self, reach_time=11, test_time_range=(3, 35), save_path=None):
        """ç»˜åˆ¶é£é™©å‡½æ•°å½¢çŠ¶ï¼ˆä¿®æ­£ç‰ˆæœ¬ï¼‰"""
        test_times = np.linspace(test_time_range[0], test_time_range[1], 500)
        risks = [self.calculate_individual_risk(t, reach_time) for t in test_times]

        plt.figure(figsize=(16, 12))

        # åˆ›å»ºå­å›¾
        gs = plt.GridSpec(3, 2, hspace=0.4, wspace=0.3)

        # ä¸»å›¾ï¼šå®Œæ•´çš„é£é™©å‡½æ•°
        ax1 = plt.subplot(gs[0, :])
        plt.plot(test_times, risks, 'b-', linewidth=3, label='Enhanced Risk Function')

        # æ ‡è®°è¾¾æ ‡æ—¶é—´ç‚¹
        plt.axvline(x=reach_time, color='red', linestyle='--', linewidth=2,
                    label=f'Reach Time = {reach_time} weeks')

        # åˆ†åˆ«ç»˜åˆ¶æ—©æœŸå’Œæ™šæœŸåŒºåŸŸ
        early_times = test_times[test_times < reach_time]
        late_times = test_times[test_times > reach_time]

        if len(early_times) > 0:
            early_risks = [self.calculate_individual_risk(t, reach_time) for t in early_times]
            plt.fill_between(early_times, early_risks, alpha=0.3, color='green',
                             label='Early Detection (Quadratic)')

        if len(late_times) > 0:
            late_risks = [self.calculate_individual_risk(t, reach_time) for t in late_times]
            plt.fill_between(late_times, late_risks, alpha=0.3, color='orange',
                             label='Late Detection (Enhanced Exponential)')

        # æ ‡è®°åˆ†æ®µè¾¹ç•Œï¼ˆåŸºäºå»¶è¿Ÿæ—¶é—´ï¼‰
        '''plt.axvline(x=reach_time + 12, color='orange', linestyle=':', alpha=0.7,
                    label='Segment 1â†’2 (delay=12w)')
        plt.axvline(x=reach_time + 27, color='red', linestyle=':', alpha=0.7,
                    label='Segment 2â†’3 (delay=27w)')'''

        plt.xlabel('Test Time (weeks)')
        plt.ylabel('Risk')
        plt.title(f'Enhanced Medical Risk Function (Reach Time = {reach_time} weeks)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.yscale('log')

        # å­å›¾1ï¼šæ—©æœŸæ£€æµ‹éƒ¨åˆ†è¯¦ç»†æ˜¾ç¤º
        ax2 = plt.subplot(gs[1, 0])
        early_range = np.linspace(max(reach_time - 8, test_time_range[0]), reach_time, 100)
        early_risks = [self.calculate_individual_risk(t, reach_time) for t in early_range]
        plt.plot(early_range, early_risks, 'g-', linewidth=3)
        plt.axvline(x=reach_time, color='red', linestyle='--', alpha=0.7)
        plt.xlabel('Test Time (weeks)')
        plt.ylabel('Risk')
        plt.title('Early Detection: Quadratic Risk')
        plt.grid(True, alpha=0.3)

        # å­å›¾2ï¼šæ™šæœŸæ£€æµ‹éƒ¨åˆ†è¯¦ç»†æ˜¾ç¤ºï¼ˆçº¿æ€§åæ ‡ï¼‰
        ax3 = plt.subplot(gs[1, 1])
        late_range = np.linspace(reach_time, min(reach_time + 30, test_time_range[1]), 200)
        late_risks = [self.calculate_individual_risk(t, reach_time) for t in late_range]
        plt.plot(late_range, late_risks, 'orange', linewidth=3)
        plt.axvline(x=reach_time, color='red', linestyle='--', alpha=0.7)
        plt.xlabel('Test Time (weeks)')
        plt.ylabel('Risk')
        plt.title('Late Detection: Enhanced Exponential (Linear Scale)')
        plt.grid(True, alpha=0.3)

        ''''# å­å›¾3ï¼šé£é™©æ–œç‡åˆ†æ
        ax4 = plt.subplot(gs[2, 0])
        # è®¡ç®—å»¶è¿Ÿ0-40å‘¨çš„é£é™©å€¼å’Œæ–œç‡
        delays = np.linspace(0, 40, 200)
        delay_risks = [self.calculate_individual_risk(reach_time + d, reach_time) for d in delays]

        plt.plot(delays, delay_risks, 'r-', linewidth=3, label='Risk vs Delay')
        plt.axvline(x=12, color='orange', linestyle=':', alpha=0.7, label='Boundary 1 (12w)')
        plt.axvline(x=27, color='red', linestyle=':', alpha=0.7, label='Boundary 2 (27w)')
        plt.xlabel('Delay (weeks)')
        plt.ylabel('Risk')
        plt.title('Risk vs Delay Time')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.yscale('log')

        # å­å›¾4ï¼šé£é™©å¢é•¿ç‡åˆ†æ
        ax5 = plt.subplot(gs[2, 1])
        # æ˜¾ç¤ºå…³é”®æ—¶é—´ç‚¹çš„é£é™©å€¼
        key_delays = [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36]
        key_risks = [self.calculate_individual_risk(reach_time + d, reach_time) for d in key_delays]

        plt.bar(key_delays, key_risks, alpha=0.7, color=['lightblue'] * 4 + ['orange'] * 4 + ['red'] * 5)
        plt.axvline(x=12, color='orange', linestyle=':', alpha=0.7)
        plt.axvline(x=27, color='red', linestyle=':', alpha=0.7)
        plt.xlabel('Delay (weeks)')
        plt.ylabel('Risk')
        plt.title('Risk at Key Delay Points')
        plt.grid(True, alpha=0.3)
        plt.yscale('log')'''

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')

        plt.show()


    def find_optimal_test_time(self, reach_times, test_time_range=(10, 30)):
        """ä¸ºç»™å®šçš„è¾¾æ ‡æ—¶é—´åˆ†å¸ƒæ‰¾åˆ°æœ€ä¼˜æ£€æµ‹æ—¶é—´"""
        test_times = np.linspace(test_time_range[0], test_time_range[1], 200)
        risks = [self.calculate_group_risk(t, reach_times)[0] for t in test_times]

        optimal_idx = np.argmin(risks)
        optimal_time = test_times[optimal_idx]
        optimal_risk = risks[optimal_idx]

        return optimal_time, optimal_risk


class RobustBMIGroupingOptimizer:
    """é²æ£’çš„BMIåˆ†ç»„ä¼˜åŒ–å™¨ - è§£å†³å¤§ç»„æ•°ä¼˜åŒ–é—®é¢˜"""

    def __init__(self, data, risk_function, min_group_size=6, max_groups=6,
                 optimization_attempts=5):
        """
        å‚æ•°ï¼š
        - data: åŒ…å«BMIå’Œé¢„è®¡åˆ°è¾¾æ—¶é—´çš„DataFrame
        - risk_function: å¢å¼ºçš„åŒ»å­¦é£é™©å‡½æ•°å¯¹è±¡
        - min_group_size: æ¯ç»„æœ€å°æ ·æœ¬é‡ï¼ˆé™ä½è¦æ±‚ï¼‰
        - max_groups: æœ€å¤§åˆ†ç»„æ•°
        - optimization_attempts: æ¯ä¸ªåˆ†ç»„çš„ä¼˜åŒ–å°è¯•æ¬¡æ•°
        """
        self.data = data.copy()
        self.risk_function = risk_function
        self.min_group_size = min_group_size
        self.max_groups = max_groups
        self.optimization_attempts = optimization_attempts

        # æ•°æ®é¢„å¤„ç†
        self.bmi_values = self.data['BMI'].values
        self.reach_times = self.data['é¢„è®¡åˆ°è¾¾æ—¶é—´'].values
        self.bmi_min = self.bmi_values.min()
        self.bmi_max = self.bmi_values.max()

        # å¯è¡Œæ€§æ£€æŸ¥
        max_feasible_groups = len(self.data) // self.min_group_size
        if self.max_groups > max_feasible_groups:
            print(f"âš ï¸ è­¦å‘Š: æ ·æœ¬é‡{len(self.data)}æœ€å¤šæ”¯æŒ{max_feasible_groups}ç»„(æ¯ç»„â‰¥{self.min_group_size}æ ·æœ¬)")
            self.max_groups = min(self.max_groups, max_feasible_groups)

        self.best_solution = None
        self.optimization_history = []

        print(f"é²æ£’BMIåˆ†ç»„ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ:")
        print(f"  æ•°æ®é›†å¤§å°: {len(self.data)}")
        print(f"  BMIèŒƒå›´: {self.bmi_min:.1f} - {self.bmi_max:.1f}")
        print(f"  è¾¾æ ‡æ—¶é—´èŒƒå›´: {self.reach_times.min():.1f} - {self.reach_times.max():.1f} å‘¨")
        print(f"  æœ€å¤§å¯è¡Œåˆ†ç»„æ•°: {self.max_groups}")
        print(f"  æ¯ç»„æœ€å°æ ·æœ¬é‡: {self.min_group_size}")

    def assign_groups(self, boundaries):
        """æ ¹æ®è¾¹ç•Œç‚¹åˆ†é…ç»„åˆ«"""
        group_assignments = np.zeros(len(self.bmi_values), dtype=int)

        for i, bmi in enumerate(self.bmi_values):
            group = 0
            for boundary in boundaries:
                if bmi >= boundary:
                    group += 1
                else:
                    break
            group_assignments[i] = group

        return group_assignments

    def evaluate_solution(self, solution_vector, num_groups):
        """è¯„ä¼°è§£å†³æ–¹æ¡ˆçš„é£é™©ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰"""
        try:
            # è§£ç è§£å†³æ–¹æ¡ˆ
            boundaries = solution_vector[:num_groups - 1]
            test_times = solution_vector[num_groups - 1:num_groups - 1 + num_groups]

            # ç¡®ä¿è¾¹ç•Œç‚¹å•è°ƒé€’å¢ä¸”æœ‰åˆç†é—´éš”
            boundaries = np.sort(boundaries)
            boundaries = np.clip(boundaries, self.bmi_min + 0.1, self.bmi_max - 0.1)

            # æ£€æŸ¥è¾¹ç•Œç‚¹é—´è·
            if len(boundaries) > 1:
                min_gap = np.min(np.diff(boundaries))
                if min_gap < 1.0:  # BMIé—´è·è‡³å°‘1.0
                    return 50000.0

            # ç¡®ä¿æ£€æµ‹æ—¶é—´åœ¨åˆç†èŒƒå›´å†…
            test_times = np.clip(test_times, 10.0, 28.0)

            group_assignments = self.assign_groups(boundaries)

            total_risk = 0
            total_weight = 0
            penalty = 0

            # æ£€æŸ¥æ¯ç»„çš„æ ·æœ¬é‡å’Œé£é™©
            group_sizes = []
            for group_id in range(num_groups):
                group_mask = group_assignments == group_id
                group_size = np.sum(group_mask)
                group_sizes.append(group_size)

                if group_size < self.min_group_size:
                    # æ ·æœ¬é‡ä¸è¶³çš„ä¸¥é‡æƒ©ç½šï¼Œéšåˆ†ç»„æ•°å¢åŠ 
                    penalty_factor = 2000.0 * (1 + 0.2 * num_groups)
                    penalty += penalty_factor * (self.min_group_size - group_size) ** 2

                if group_size > 0:
                    group_reach_times = self.reach_times[group_mask]
                    test_time = test_times[group_id]

                    group_risk, _ = self.risk_function.calculate_group_risk(
                        test_time, group_reach_times
                    )

                    # å¯¹è¿‡å°çš„ç»„ç»™äºˆé¢å¤–æƒ©ç½š
                    if group_size < self.min_group_size * 1.5:
                        group_risk *= (1 + 0.2 * (self.min_group_size * 1.5 - group_size))

                    total_risk += group_risk * group_size
                    total_weight += group_size

            # æ£€æŸ¥ç»„å¤§å°åˆ†å¸ƒçš„å‡è¡¡æ€§
            if len(group_sizes) > 1:
                size_std = np.std(group_sizes)
                size_mean = np.mean(group_sizes)
                if size_mean > 0:
                    cv = size_std / size_mean  # å˜å¼‚ç³»æ•°
                    if cv > 1.0:  # åˆ†å¸ƒè¿‡ä¸å‡è¡¡
                        penalty += 100.0 * cv

            if total_weight == 0:
                return 50000.0

            avg_risk = total_risk / total_weight + penalty

            # æ·»åŠ è½»å¾®çš„å¤æ‚åº¦æƒ©ç½š
            complexity_penalty = 0.001 * (num_groups - 2) ** 1.5
            avg_risk += complexity_penalty

            return avg_risk

        except Exception as e:
            return 50000.0

    def get_smart_initial_boundaries(self, num_groups):
        """æ™ºèƒ½ç”Ÿæˆåˆå§‹è¾¹ç•Œç‚¹"""
        # åŸºäºBMIåˆ†å¸ƒçš„åˆ†ä½æ•°æ¥è®¾ç½®åˆå§‹è¾¹ç•Œ
        if num_groups <= 2:
            return []

        # ä½¿ç”¨åˆ†ä½æ•°ä½œä¸ºåˆå§‹è¾¹ç•Œ
        quantiles = np.linspace(1 / (num_groups), 1 - 1 / (num_groups), num_groups - 1)
        boundaries = np.quantile(self.bmi_values, quantiles)

        # ç¡®ä¿è¾¹ç•Œç‚¹æœ‰åˆç†é—´éš”
        min_gap = 1.5
        for i in range(1, len(boundaries)):
            if boundaries[i] - boundaries[i - 1] < min_gap:
                boundaries[i] = boundaries[i - 1] + min_gap

        # è°ƒæ•´è¶…å‡ºèŒƒå›´çš„è¾¹ç•Œç‚¹
        boundaries = np.clip(boundaries, self.bmi_min + 1, self.bmi_max - 1)

        return boundaries

    def optimize_for_k_groups(self, num_groups):
        """ä¸ºæŒ‡å®šæ•°é‡çš„ç»„è¿›è¡Œä¼˜åŒ–ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰"""
        print(f"  ä¼˜åŒ– {num_groups} ä¸ªåˆ†ç»„...")

        # æ£€æŸ¥å¯è¡Œæ€§
        min_required_samples = num_groups * self.min_group_size
        if len(self.data) < min_required_samples:
            print(f"    æ ·æœ¬é‡ä¸è¶³: éœ€è¦{min_required_samples}, å®é™…{len(self.data)}")
            return {'success': False, 'num_groups': num_groups}

        # æ™ºèƒ½è®¾ç½®è¾¹ç•Œç‚¹èŒƒå›´
        bmi_range = self.bmi_max - self.bmi_min
        min_gap = max(1.0, bmi_range / (num_groups * 3))  # ç¡®ä¿æœ‰è¶³å¤Ÿé—´éš”

        bounds = []

        # è¾¹ç•Œç‚¹çš„è¾¹ç•Œ - æ›´æ™ºèƒ½çš„è®¾ç½®
        for i in range(num_groups - 1):
            lower = self.bmi_min + min_gap * (i + 1)
            upper = self.bmi_max - min_gap * (num_groups - i - 1)
            bounds.append((lower, upper))

        # æ£€æµ‹æ—¶é—´çš„è¾¹ç•Œ
        for i in range(num_groups):
            bounds.append((10.0, 28.0))

        # å¤šæ¬¡å°è¯•ä¼˜åŒ–
        best_result = None
        best_risk = float('inf')

        # åŠ¨æ€è°ƒæ•´ç®—æ³•å‚æ•°
        max_iter = min(600 + num_groups * 150, 1500)
        pop_size = min(60 + num_groups * 15, 150)

        for attempt in range(self.optimization_attempts):
            try:
                # ä¸ºæ¯æ¬¡å°è¯•ä½¿ç”¨ä¸åŒçš„å‚æ•°
                mutation_range = (0.3 + attempt * 0.1, 1.8 + attempt * 0.1)
                recombination = 0.7 + attempt * 0.05

                result = differential_evolution(
                    lambda x: self.evaluate_solution(x, num_groups),
                    bounds,
                    seed=42 + attempt * 7,
                    maxiter=max_iter,
                    popsize=pop_size,
                    mutation=mutation_range,
                    recombination=min(recombination, 0.9),
                    polish=True,
                    atol=1e-8,
                    tol=1e-8,
                    workers=1,
                    updating='deferred' if num_groups > 4 else 'immediate'
                )

                if result.success and result.fun < best_risk and result.fun < 40000:
                    best_result = result
                    best_risk = result.fun
                    print(f"    å°è¯• {attempt + 1}: é£é™© = {result.fun:.4f} âœ“")
                else:
                    print(f"    å°è¯• {attempt + 1}: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}, é£é™© = {result.fun:.1f}")

            except Exception as e:
                print(f"    å°è¯• {attempt + 1} å¼‚å¸¸: {str(e)}")
                continue

        if best_result is not None:
            boundaries = best_result.x[:num_groups - 1]
            test_times = best_result.x[num_groups - 1:num_groups - 1 + num_groups]

            # ç¡®ä¿è¾¹ç•Œç‚¹å•è°ƒé€’å¢
            boundaries = np.sort(boundaries)
            boundaries = np.clip(boundaries, self.bmi_min + 0.5, self.bmi_max - 0.5)
            test_times = np.clip(test_times, 10.0, 28.0)

            # éªŒè¯è§£çš„å¯è¡Œæ€§
            group_assignments = self.assign_groups(boundaries)
            group_sizes = [np.sum(group_assignments == i) for i in range(num_groups)]

            if all(size >= self.min_group_size for size in group_sizes):
                print(f"    âœ“ æˆåŠŸ! ç»„å¤§å°: {group_sizes}")
                return {
                    'num_groups': num_groups,
                    'boundaries': boundaries,
                    'test_times': test_times,
                    'risk': best_result.fun,
                    'success': True,
                    'optimization_result': best_result,
                    'group_sizes': group_sizes
                }
            else:
                print(f"    âœ— è§£ä¸æ»¡è¶³æœ€å°ç»„å¤§å°è¦æ±‚: {group_sizes}")
                return {'success': False, 'num_groups': num_groups}
        else:
            print(f"    âœ— æ‰€æœ‰å°è¯•éƒ½å¤±è´¥")
            return {'success': False, 'num_groups': num_groups}

    def run_optimization(self):
        """è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–è¿‡ç¨‹"""
        print("=" * 70)
        print("å¼€å§‹é²æ£’BMIåˆ†ç»„ä¼˜åŒ–")
        print("=" * 70)

        best_solution = None
        best_risk = float('inf')
        all_solutions = []

        # å°è¯•ä¸åŒçš„åˆ†ç»„æ•°
        for k in range(2, self.max_groups + 1):
            print(f"\nã€{k}ç»„ä¼˜åŒ–ã€‘")
            solution = self.optimize_for_k_groups(k)

            if solution['success']:
                all_solutions.append(solution)
                group_sizes = solution.get('group_sizes', [])
                test_times = solution['test_times']
                boundaries = solution['boundaries']

                print(f"  æˆåŠŸ! é£é™© = {solution['risk']:.4f}")
                print(f"  ç»„å¤§å°: {group_sizes}")
                print(f"  æœ€ä½³NIPTæ—¶é—´: {[f'{t:.1f}å‘¨' for t in test_times]}")

                # æ˜¾ç¤ºBMIåˆ†ç»„èŒƒå›´å’Œå¯¹åº”çš„æ£€æµ‹æ—¶é—´
                print(f"  åˆ†ç»„æ–¹æ¡ˆ:")
                if k == 1:
                    print(f"    ç»„1: BMI [{self.bmi_min:.1f}, {self.bmi_max:.1f}] â†’ æ£€æµ‹æ—¶é—´: {test_times[0]:.1f}å‘¨")
                else:
                    # ç¬¬ä¸€ç»„
                    print(f"    ç»„1: BMI [{self.bmi_min:.1f}, {boundaries[0]:.1f}) â†’ æ£€æµ‹æ—¶é—´: {test_times[0]:.1f}å‘¨")
                    # ä¸­é—´ç»„
                    for i in range(1, len(boundaries)):
                        print(
                            f"    ç»„{i + 1}: BMI [{boundaries[i - 1]:.1f}, {boundaries[i]:.1f}) â†’ æ£€æµ‹æ—¶é—´: {test_times[i]:.1f}å‘¨")
                    # æœ€åä¸€ç»„
                    print(
                        f"    ç»„{len(boundaries) + 1}: BMI [{boundaries[-1]:.1f}, {self.bmi_max:.1f}] â†’ æ£€æµ‹æ—¶é—´: {test_times[-1]:.1f}å‘¨")

                if solution['risk'] < best_risk:
                    best_risk = solution['risk']
                    best_solution = solution
            else:
                print(f"  å¤±è´¥ - å¯èƒ½åŸå› : æ ·æœ¬é‡ä¸è¶³æˆ–çº¦æŸå†²çª")

        if best_solution is not None:
            self.best_solution = best_solution
            self.optimization_history = all_solutions

            print(f"\nğŸ¯ æœ€ä½³æ–¹æ¡ˆ: {best_solution['num_groups']}ç»„, é£é™© = {best_risk:.4f}")
            return best_solution
        else:
            print("\nâŒ æ‰€æœ‰ä¼˜åŒ–æ–¹æ¡ˆéƒ½å¤±è´¥äº†ï¼")
            print("å»ºè®®: å‡å°‘æœ€å¤§åˆ†ç»„æ•°æˆ–é™ä½æœ€å°ç»„å¤§å°è¦æ±‚")
            return None

    def get_detailed_results(self):
        """è·å–è¯¦ç»†çš„ä¼˜åŒ–ç»“æœ"""
        if self.best_solution is None:
            print("æ²¡æœ‰å¯ç”¨çš„ä¼˜åŒ–ç»“æœï¼")
            return None

        solution = self.best_solution
        boundaries = solution['boundaries']
        test_times = solution['test_times']
        num_groups = solution['num_groups']

        # åˆ†é…ç»„åˆ«
        group_assignments = self.assign_groups(boundaries)

        # æ„å»ºè¾¹ç•Œä¿¡æ¯
        bmi_ranges = []
        if num_groups == 1:
            bmi_ranges.append(f"[{self.bmi_min:.1f}, {self.bmi_max:.1f}]")
        else:
            # ç¬¬ä¸€ç»„
            bmi_ranges.append(f"[{self.bmi_min:.1f}, {boundaries[0]:.1f})")

            # ä¸­é—´ç»„
            for i in range(1, len(boundaries)):
                bmi_ranges.append(f"[{boundaries[i - 1]:.1f}, {boundaries[i]:.1f})")

            # æœ€åä¸€ç»„
            bmi_ranges.append(f"[{boundaries[-1]:.1f}, {self.bmi_max:.1f}]")

        # è®¡ç®—æ¯ç»„çš„è¯¦ç»†ç»Ÿè®¡
        group_details = []
        total_risk = 0
        total_samples = 0

        for group_id in range(num_groups):
            group_mask = group_assignments == group_id
            group_bmis = self.bmi_values[group_mask]
            group_reach_times = self.reach_times[group_mask]
            test_time = test_times[group_id]

            group_size = len(group_reach_times)

            # ä½¿ç”¨å¢å¼ºé£é™©å‡½æ•°è®¡ç®—è¯¦ç»†ä¿¡æ¯
            risk_details = self.risk_function.calculate_group_risk(
                test_time, group_reach_times, return_details=True
            )

            # è®¡ç®—è¾¾æ ‡æ—¶é—´ç»Ÿè®¡
            reach_time_stats = {
                'mean': np.mean(group_reach_times),
                'median': np.median(group_reach_times),
                'std': np.std(group_reach_times),
                'min': np.min(group_reach_times),
                'max': np.max(group_reach_times)
            }

            # è®¡ç®—æ—¶é—´å·®ç»Ÿè®¡
            time_diffs = group_reach_times - test_time

            group_details.append({
                'group_id': group_id + 1,
                'bmi_range': bmi_ranges[group_id],
                'size': group_size,
                'avg_bmi': np.mean(group_bmis),
                'optimal_test_time': test_time,
                'group_risk': risk_details['avg_risk'],
                'detection_success_rate': risk_details['detection_success_rate'],
                'early_count': risk_details['early_count'],
                'late_count': risk_details['late_count'],
                'on_time_count': risk_details['on_time_count'],
                'reach_time_stats': reach_time_stats,
                'avg_time_diff': np.mean(time_diffs),
                'std_time_diff': np.std(time_diffs)
            })

            total_risk += risk_details['avg_risk'] * group_size
            total_samples += group_size

        overall_risk = total_risk / total_samples

        return {
            'solution': solution,
            'group_details': group_details,
            'overall_risk': overall_risk,
            'group_assignments': group_assignments
        }

    def print_detailed_results(self):
        """æ‰“å°è¯¦ç»†ç»“æœ"""
        detailed_results = self.get_detailed_results()

        if detailed_results is None:
            return

        print("\n" + "=" * 90)
        print("é²æ£’BMIåˆ†ç»„ä¼˜åŒ–è¯¦ç»†ç»“æœ")
        print("=" * 90)

        print(f"æœ€ä¼˜åˆ†ç»„æ•°: {self.best_solution['num_groups']}")
        print(f"æ€»ä½“é£é™©: {detailed_results['overall_risk']:.4f}")

        print(f"\nå„ç»„è¯¦ç»†ä¿¡æ¯:")
        print("-" * 90)

        for group in detailed_results['group_details']:
            print(f"\nç»„ {group['group_id']}:")
            print(f"  BMIèŒƒå›´: {group['bmi_range']}")
            print(f"  æ ·æœ¬æ•°é‡: {group['size']}")
            print(f"  å¹³å‡BMI: {group['avg_bmi']:.2f}")
            print(f"  æœ€ä½³æ£€æµ‹æ—¶é—´: {group['optimal_test_time']:.1f} å‘¨")
            print(f"  ç»„é£é™©: {group['group_risk']:.4f}")
            print(f"  æ£€æµ‹æˆåŠŸç‡: {group['detection_success_rate']:.1%}")

            print(f"  æ£€æµ‹æ—¶æœºåˆ†å¸ƒ:")
            print(f"    æ—©æœŸæ£€æµ‹: {group['early_count']} äºº")
            print(f"    å‡†æ—¶æ£€æµ‹: {group['on_time_count']} äºº")
            print(f"    æ™šæœŸæ£€æµ‹: {group['late_count']} äºº")
            print(f"    å¹³å‡æ—¶é—´å·®: {group['avg_time_diff']:.2f} å‘¨ (Â±{group['std_time_diff']:.2f})")

            stats = group['reach_time_stats']
            print(f"  é¢„è®¡è¾¾æ ‡æ—¶é—´ç»Ÿè®¡:")
            print(f"    å‡å€¼: {stats['mean']:.1f}å‘¨, ä¸­ä½æ•°: {stats['median']:.1f}å‘¨")
            print(f"    èŒƒå›´: {stats['min']:.1f}-{stats['max']:.1f}å‘¨, æ ‡å‡†å·®: {stats['std']:.1f}å‘¨")

        print("\n" + "=" * 90)

        # ç”Ÿæˆæœ€ç»ˆå»ºè®®
        print("ä¸´åºŠåº”ç”¨å»ºè®®:")
        print("-" * 50)

        for group in detailed_results['group_details']:
            if group['group_risk'] < 2:
                risk_level = "ä½é£é™©"
            elif group['group_risk'] < 5:
                risk_level = "ä¸­é£é™©"
            else:
                risk_level = "é«˜é£é™©"

            early_rate = group['early_count'] / group['size'] * 100
            late_rate = group['late_count'] / group['size'] * 100

            print(f"BMI {group['bmi_range']}: ç¬¬ {group['optimal_test_time']:.1f} å‘¨æ£€æµ‹")
            print(f"  â†’ {risk_level}, æˆåŠŸç‡ {group['detection_success_rate']:.1%}, "
                  f"æ—©æ£€ {early_rate:.1f}%, æ™šæ£€ {late_rate:.1f}%")


def run_enhanced_medical_optimization(prediction_results_file='reach_time_results_Q3.csv'):
    """è¿è¡Œå¢å¼ºåŒ»å­¦é£é™©ä¼˜åŒ–çš„ä¸»å‡½æ•°"""
    try:
        # è¯»å–é¢„æµ‹ç»“æœ
        print("è¯»å–é¢„æµ‹ç»“æœ...")
        data = pd.read_csv(prediction_results_file)
        print(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(data)} ä¸ªæ ·æœ¬")

        # åˆ›å»ºå¢å¼ºçš„åŒ»å­¦é£é™©å‡½æ•°ï¼ˆå¤§å¹…å¢åŠ è¿‡æ™šæ£€æµ‹æ–œç‡ï¼‰
        risk_function = EnhancedMedicalRiskFunction(
            early_quadratic_coeff=0.02,  # æ—©æœŸæ£€æµ‹äºŒæ¬¡å‡½æ•°ç³»æ•°
            late_exp_base_1=0.3,  # ç¬¬1æ®µæŒ‡æ•°åŸºæ•°
            late_exp_rate_1=0.15,  # ç¬¬1æ®µæŒ‡æ•°å¢é•¿ç‡
            late_exp_base_2=2.5,  # ç¬¬2æ®µæŒ‡æ•°åŸºæ•°ï¼ˆå¤§å¹…å¢åŠ ï¼‰
            late_exp_rate_2=0.40,  # ç¬¬2æ®µæŒ‡æ•°å¢é•¿ç‡ï¼ˆå¤§å¹…å¢åŠ ï¼‰
            late_exp_base_3=6.0,  # ç¬¬3æ®µæŒ‡æ•°åŸºæ•°ï¼ˆå¤§å¹…å¢åŠ ï¼‰
            late_exp_rate_3=0.65,  # ç¬¬3æ®µæŒ‡æ•°å¢é•¿ç‡ï¼ˆæå¤§å¢åŠ ï¼‰
            base_risk=1.0  # åŸºç¡€é£é™©
        )

        # å±•ç¤ºå¢å¼ºçš„é£é™©å‡½æ•°ç‰¹æ€§
        print("\nå±•ç¤ºå¢å¼ºåŒ»å­¦é£é™©å‡½æ•°ç‰¹æ€§...")
        risk_function.plot_risk_function(reach_time=11, save_path='exp_medical_risk_function.png')

        # åˆ›å»ºé²æ£’ä¼˜åŒ–å™¨
        optimizer = RobustBMIGroupingOptimizer(
            data=data,
            risk_function=risk_function,
            min_group_size=6,  # é™ä½æœ€å°ç»„å¤§å°è¦æ±‚
            max_groups=5,  # æœ€å¤§åˆ†ç»„æ•°
            optimization_attempts=1  # æ¯ä¸ªåˆ†ç»„å°è¯•5æ¬¡
        )

        # è¿è¡Œä¼˜åŒ–
        best_solution = optimizer.run_optimization()

        if best_solution is not None:
            # æ‰“å°è¯¦ç»†ç»“æœ
            optimizer.print_detailed_results()

            # ç»˜åˆ¶æœ€ç»ˆåˆ†ç»„ç»“æœå¯è§†åŒ–
            # print("\nç”Ÿæˆæœ€ç»ˆåˆ†ç»„ç»“æœå¯è§†åŒ–...")
            # optimizer.plot_final_grouping_results('final_bmi_grouping_visualization.png')

            # ä¿å­˜ç»“æœ
            detailed_results = optimizer.get_detailed_results()
            result_data = data.copy()
            result_data['Group'] = detailed_results['group_assignments'] + 1

            # æ·»åŠ æ¯ç»„çš„æœ€ä½³æ£€æµ‹æ—¶é—´å’Œé£é™©ä¿¡æ¯
            for group in detailed_results['group_details']:
                group_mask = result_data['Group'] == group['group_id']
                result_data.loc[group_mask, 'Optimal_Test_Time'] = group['optimal_test_time']
                result_data.loc[group_mask, 'Group_Risk'] = group['group_risk']
                result_data.loc[group_mask, 'Detection_Success_Rate'] = group['detection_success_rate']

            result_data.to_csv('exp_medical_bmi_grouping_results.csv', index=False)
            print(f"\nç»“æœå·²ä¿å­˜åˆ°: exp_medical_bmi_grouping_results.csv")

            return optimizer
        else:
            print("\nä¼˜åŒ–å¤±è´¥ï¼")
            return None

    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    optimizer = run_enhanced_medical_optimization()